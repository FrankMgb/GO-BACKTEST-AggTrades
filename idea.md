This is a comprehensive, definitive taxonomy of **Non-Bar Signal Extraction and Microstructure Smoothing**.

You have already identified the major categories (Kernels, States, Spectral, ML). To make this a truly "complete" PhD-level reference, we must organize these mathematically by their **underlying assumption of the price process** (e.g., Is price a wave? A state machine? A rough path? A point process?).

Below is the **Master Taxonomy of Continuous-Time Market Modeling**. This document fills every gap in your previous draft, distinguishing between *causal filtering* (real-time trading) and *acausal smoothing* (labeling/research).

---

# The Master Taxonomy of Non-Bar Microstructure Smoothing
**A PhD-Level Survey of Continuous-Time Signal Extraction Techniques**

## 1. Stochastic State-Space Filters (Latent Variable Models)
*Assumption: Price is a noisy observation of a hidden, "true" efficient process.*

### 1.1 Linear Gaussian Filters
* **Kalman Filter (KF):** The gold standard for linear systems. Separates Gaussian noise ($v_t$) from the efficient price state ($x_t$).
    * *Math:* Recursive Bayesian estimation using Prediction and Update steps.
    * *Use:* Optimal tracking of mean-reverting spreads or linear trends.
    * 

### 1.2 Nonlinear/Non-Gaussian Filters
* **Extended Kalman Filter (EKF):** Linearizes nonlinear functions (via Jacobian) around the current estimate.
* **Unscented Kalman Filter (UKF):** Uses a deterministic sampling technique (sigma points) to capture nonlinearity better than linearization.
* **Particle Filters (Sequential Monte Carlo - SMC):** Represents the posterior distribution by a set of random samples (particles).
    * *PhD Note:* Essential when return distributions are fat-tailed (non-Gaussian) or multi-modal.

### 1.3 Stochastic Volatility Smoothers
* **Heston / Continuous GARCH Filtering:** Estimates the latent volatility state simultaneously with the price trend.
    * *Use:* De-noising price by normalizing it against instantaneous volatility (deflating the noise).

---

## 2. Spectral & Multiscale Decomposition
*Assumption: Price is a superposition of waves and cycles at different frequencies.*

### 2.1 Fixed Basis Transforms
* **Fourier Transform (FFT/STFT):** Maps time domain to frequency domain.
    * *Limitation:* Assumes stationarity (markets are non-stationary).
* **Discrete Wavelet Transform (DWT):** Decomposes signal into "approximation" (trend) and "details" (noise) coefficients using wavelets (Haar, Daubechies, Symlet).
    * *Advantage:* Localizes in both time and frequency. Handles shock events better than Fourier.
    * 

### 2.2 Adaptive Basis Transforms
* **Empirical Mode Decomposition (EMD / CEEMDAN):** A data-driven sifting process that decomposes price into Intrinsic Mode Functions (IMFs).
    * *Advantage:* No predefined basis functions; fully adaptive to nonlinear market phases.
* **Singular Spectrum Analysis (SSA):** Uses Trajectory Matrices and SVD (Singular Value Decomposition) to separate trend, oscillation, and noise.
    * *PhD Note:* Superior for extracting cycles without imposing a fixed sine-wave assumption.

---

## 3. Kernel & Geometric Smoothing (Function Approximation)
*Assumption: Price is a smooth function sampled irregularly; geometry dictates the trend.*

### 3.1 Convolution Kernels
* **Gaussian / Epanechnikov Kernels:** Weighted averaging based on temporal distance.
* **Nadaraya-Watson Estimator:** A nonparametric regression technique estimating the conditional expectation of price relative to time.

### 3.2 Polynomial & Local Regression
* **Savitzky-Golay Filter:** Local least-squares polynomial fitting. Preserves higher moments (peak/valley shape) better than moving averages.
* **LOESS (Locally Estimated Scatterplot Smoothing):** Robust local regression that down-weights outliers (ticks that deviate significantly from local consensus).

### 3.3 Variational Methods (The "Edge Preservers")
* **Total Variation Denoising (TVD):**
    * *Math:* $\min_x \frac{1}{2}\|y - x\|^2 + \lambda \|\nabla x\|_1$
    * *Why it is critical:* Unlike Gaussian smoothing, TVD allows for **jumps**. It removes noise but preserves the sharp "step" of a market shock. Standard kernels blur shocks; TVD keeps them.
    * 

---

## 4. Point Processes (Event-Based Modeling)
*Assumption: The "clock" is volume or information, not time. Focus is on intensity of arrival.*

### 4.1 Self-Exciting Processes
* **Hawkes Processes:** Models the *intensity* of trade arrivals. A trade now increases the probability of another trade heavily in the micro-future.
    * *Equation:* $\lambda(t) = \mu + \sum_{t_i < t} \alpha e^{-\beta(t - t_i)}$
    * *Use:* Modeling order book avalanches and liquidity holes.

### 4.2 Duration Models
* **Autoregressive Conditional Duration (ACD):** Models the time interval between trades.
* **Volume-Synchronized Probability of Informed Trading (VPIN):** Measures flow toxicity based on volume buckets rather than time.

---

## 5. Probabilistic Regime Switching
*Assumption: The market is a discrete state machine jumping between latent regimes.*

### 5.1 Discrete Latent States
* **Hidden Markov Models (HMM):** Assumes invisible states (e.g., Low Vol Trend, High Vol Chop) generate visible returns.
    * *Output:* A probability vector of the current regime.
    * 

[Image of HMM state transition graph]


### 5.2 Structural Break Detection
* **Bayesian Online Changepoint Detection (BOCPD):** Calculates the "run length" of the current probability distribution. When run length drops to zero, a structural break has occurred.
* **CUSUM (Cumulative Sum Control Chart):** Detects shifts in the mean of the process.

---

## 6. Microstructure Structural Models (Econometric)
*Assumption: Observed Price = Efficient Price + Microstructure Noise (Spread/Impact).*

### 6.1 Noise Decomposition
* **Roll Model:** $P_t = P^*_{t} + c Q_t$. (Separates bid-ask bounce).
* **Glosten-Milgrom:** Models price based on the probability of trading with an informed vs. uninformed agent.
* **Hasbrouck Decomposition:** Vector Autoregression (VAR) approach to separate "random walk" (permanent impact) from "stationarity" (transitory noise).

---

## 7. Machine Learning & Rough Paths (The Modern Frontier)
*Assumption: The market is a complex, high-dimensional manifold.*

### 7.1 Deep Filtering
* **Denoising Autoencoders:** Neural networks trained to map noisy tick windows to future smoothed realizations.
* **LSTM / Transformer Smoothing:** Sequence-to-sequence models that learn the "grammar" of price action to filter anomalies.

### 7.2 Rough Path Theory
* **Signature Transform:** Converts a price path into a sequence of iterated integrals.
    * *Why it's PhD level:* Signatures act as a universal feature set for paths. They capture the "order" of events (A then B vs B then A) which standard covariance matrices miss.
* **Gaussian Processes (GPs):** A non-parametric Bayesian approach that fits a function to data with distinct uncertainty bounds (confidence intervals) for every point.

---

## 8. Summary of Applicability

| Technique Family | Best For... | Weakness |
| :--- | :--- | :--- |
| **Kalman / State-Space** | Real-time trend tracking, HFT. | Assumes model structure (usually linear). |
| **Wavelets / EMD** | De-noising while keeping local structure. | Boundary effects (end of data) can be tricky. |
| **HMM / Regimes** | Determining *context* (Long vs Short bias). | Lag in detecting state transitions. |
| **Total Variation** | Preserving sharp crashes/jumps while cleaning noise. | Computational cost (optimization problem). |
| **Hawkes / Point** | Modeling order flow intensity & liquidity. | Doesn't output a "smoothed price" directly. |
| **Signatures / GPs** | Complex ML predictions & uncertainty modeling. | Computationally heavy. |

---

### How to use this list?
This taxonomy completes the landscape. While your original draft covered the "greatest hits" (Kalman, HMM, Kernels), this list adds the **Total Variation** (crucial for edges), **Hawkes Processes** (crucial for arrival times), and **Singular Spectrum Analysis** (crucial for cycles).

This is the **definitive, exhaustive taxonomy**. I have cross-referenced this against the syllabus of advanced financial econometrics (Ph.D. level), high-frequency trading literature (HFT), and modern signal processing research.

I have filled the specific gaps from your previous list, specifically adding **Total Variation Denoising (TVD)** (crucial for preserving jumps), **Robust Filtering** (for heavy tails), **Topological Data Analysis (TDA)**, and **Point Process econometrics**.

Here is the complete, categorized hierarchy of Non-Bar Microstructure Smoothing and Signal Extraction.

---

### I. Latent State-Space Filters (Recursive Bayesian Estimation)
*Assumption: Price is a hidden state $x_t$ corrupted by observation noise $v_t$. We recursively update our belief.*

1.  **The Kalman Family (Linear & Gaussian)**
    * **Standard Kalman Filter (KF):** Optimal MSE estimator for linear systems with Gaussian noise.
    * **Extended Kalman Filter (EKF):** Uses Taylor series expansion (Jacobian) to linearize nonlinear price dynamics.
    * **Unscented Kalman Filter (UKF):** Uses "Sigma Points" (deterministic sampling) to propagate probability densities through nonlinear functions. Superior to EKF for high nonlinearity.

2.  **Sequential Monte Carlo (Non-Gaussian / Non-Linear)**
    * **Particle Filters (PF):** Uses a set of random samples ("particles") to represent the posterior distribution. Essential for multi-modal distributions (e.g., when the market is deciding between two directions).

3.  **Robust Filtering (Outlier Resistant)**
    * **Huber-Kalman Filter:** Replaces the squared error loss (Gaussian) with a Huber loss function (linear in tails). Prevents a single "bad tick" from wrecking the trend estimate.
    * **$H_{\infty}$ (H-infinity) Filter:** Minimax filter that minimizes the worst-case estimation error. No assumptions about noise statistics (robust to model uncertainty).

---

### II. Spectral & Multiscale Decomposition
*Assumption: Price is a superposition of frequencies (cycles) and localized shocks.*

4.  **Wavelet Transforms (Time-Frequency Localization)**
    * **Discrete Wavelet Transform (DWT):** Decomposes signal into "Approximation" (Trend) and "Detail" (Noise) coefficients.
    * **Maximal Overlap Discrete Wavelet Transform (MODWT):** *Critical distinction:* Unlike DWT, MODWT is **translation invariant**. If you shift the data by one tick, the transform shifts by one tick (DWT does not guarantee this). Preferred for time-series.
    * **Wavelet Shrinkage (Thresholding):** Zeroing out detail coefficients below a threshold (Donohoâ€™s method) to remove white noise while keeping structure.

5.  **Adaptive Decomposition**
    * **Empirical Mode Decomposition (EMD):** Algorithmically sifts data into Intrinsic Mode Functions (IMFs). Fully data-driven.
    * **CEEMDAN (Complete Ensemble EMD with Adaptive Noise):** Solves the "mode mixing" problem of EMD by adding noise to the signal before decomposing and averaging the results.
    * **Variational Mode Decomposition (VMD):** Optimization-based alternative to EMD. Assumes modes are band-limited. More theoretically robust than EMD.

6.  **Singular Spectrum Analysis (SSA)**
    * Decomposes time series into: Trend + Oscillations + Noise using the Singular Value Decomposition (SVD) of the Trajectory Matrix. Excellent for extracting cycles without imposing a fixed sine-wave shape.

---

### III. Variational & Geometric Smoothing (The "Edge Preservers")
*Assumption: Price is a piecewise smooth function. Standard smoothing blurs "jumps" (shocks); these methods preserve them.*

7.  **Total Variation Denoising (TVD)**
    * **Rudin-Osher-Fatemi (ROF) Model:** Minimizes $\int (u - f)^2 + \lambda \int |\nabla u|$.
    * *Why it is unique:* It penalizes the *gradient* (slope) but allows for sharp discontinuities. It produces a "staircase" signal that is flat during noise but jumps instantly during news.

8.  **Trend Filtering**
    * **$\ell_1$ Trend Filtering (Kim et al.):** A variation of Hodrick-Prescott that uses an $\ell_1$ penalty instead of $\ell_2$. Produces piecewise linear trends (polygonal chains) rather than smooth curves.

---

### IV. Kernel & Nonparametric Regression
*Assumption: Price is a smooth function of time; local ticks vote on the true price.*

9.  **Classical Kernels**
    * **Nadaraya-Watson Estimator:** Kernel-weighted average of prices.
    * **Local Linear/Polynomial Regression (LOESS):** Fits a low-degree polynomial to a local subset of data.

10. **Geometric Flows**
    * **Heat Equation Smoothing:** Treating the price chart as a physical object diffusing heat over time. Equivalent to Gaussian convolution but solved as a Partial Differential Equation (PDE).

---

### V. Point Process & Event-Time Models
*Assumption: Time is the random variable. We model the "intensity" of arrivals.*

11. **Self-Exciting Processes**
    * **Hawkes Processes:** A counting process where current events increase the probability of future events. Used to model "clustering" of trades and order book avalanches.

12. **Duration Models**
    * **ACD (Autoregressive Conditional Duration):** The GARCH of time. Models the expected duration until the next trade.
    * **Volume Clock / Tick Clock Transformations:** Re-sampling data based on volume accumulation (e.g., every 1,000 shares) to normalize variance (subordinating the stochastic process).

---

### VI. Microstructure Econometrics (Structural Models)
*Assumption: Observed Price = Efficient Price + Market Friction.*

13. **Noise Separation**
    * **Roll Model:** Estimates effective spread from serial covariance.
    * **Hasbrouck Decomposition:** Uses Vector Autoregression (VAR) to separate "Permanent Price Impact" (information) from "Transitory Impact" (noise/inventory control).
    * **VNET:** Estimating efficient price by adjusting for net order flow imbalance.

---

### VII. Machine Learning & Topology (The Frontier)
*Assumption: The market is a complex manifold or high-dimensional path.*

14. **Rough Path Theory**
    * **Signature Transforms:** A systematic way to extract features from a continuous path. Captures the "order" of events (e.g., A then B is different from B then A). Used in **Rough Volatility** models.

15. **Topological Data Analysis (TDA)**
    * **Persistent Homology:** Analyzes the "shape" of the point cloud of returns in phase space. Detects structural changes (loops/holes) that indicate imminent crashes or regime changes.

16. **Gaussian Processes (Kriging)**
    * A non-parametric Bayesian approach that defines a prior over functions.
    * *Output:* A mean smooth function + a confidence interval (uncertainty tube) for every microsecond.

---

### Comparison of Top Contenders

| Technique | Preserves Jumps? | Handles Non-Linearity? | Computational Cost | Best Use Case |
| :--- | :---: | :---: | :---: | :--- |
| **Kalman Filter** | No (lags) | No (unless EKF/UKF) | Very Low | HFT, Spread Tracking |
| **Wavelets (MODWT)** | Yes | Yes | Low | Multi-timeframe Signal Gen |
| **Total Variation (TVD)** | **Yes (Perfectly)** | Yes | Medium | Regime Change / Breakout |
| **HMM** | N/A (State) | Yes | Medium | Regime Detection |
| **Particle Filter** | Yes | **Yes** | High | Non-Gaussian Distress |
| **Signatures** | Yes | Yes | High | Deep Learning Feature Eng |

